{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-12-13 Prepare batch downloads\n",
    "So far, I understood that I need to process the data files in a way that will generate homogeneous files that we will then be able to process and feed to the training of the AI.\n",
    "\n",
    "Here, I want to prepare the files and directories containing the processed and raw files.\n",
    "\n",
    "We will create a directory structure that reflect the various experiments that we will parse and analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories and files\n",
    "tissue_ai_rootdir = \"../\"\n",
    "datadir = \"%s/data\"%(tissue_ai_rootdir)\n",
    "md_fname = \"%s/metadata.txt\"%(datadir)\n",
    "md = pd.read_csv(md_fname, sep='\\t', low_memory=False)\n",
    "fastqs = md.loc[md[\"File format\"] == \"fastq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `fastqs` is a variable that contains a Pandas Data.Frame with all the FASTQ files that we will download and process. As we saw in the previous notebook, there are single-ended and paired-ended files. Let's group the files together by experiment first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the collection of all the experiment accession IDs\n",
    "experiment_names = fastqs[\"Experiment accession\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all the experiments with an unique identifier\n",
    "for experiment_name in experiment_names :\n",
    "    \n",
    "    # get the rows in the metadata table corresponding to this experiment\n",
    "    experiment = fastqs.loc[fastqs[\"Experiment accession\"] ==  experiment_name]\n",
    "    \n",
    "    # this list will allow us to keep track of which samples we have or have not\n",
    "    # processed\n",
    "    samples_processed = []\n",
    "    \n",
    "    # iterate over all the samples in the experiment\n",
    "    for index, sample in experiment.iterrows() :\n",
    "        \n",
    "        # keep track of the sub-sample\n",
    "        replicate_idx = 1\n",
    "        \n",
    "        # this is the case in which the sample is paired-ended: we need to find\n",
    "        # which sample corresponds to the pair\n",
    "        if sample[\"Run type\"] == \"paired-ended\" :\n",
    "            \n",
    "            # the identifier of the sample allows us to know which sample is paired\n",
    "            # to the one we're visiting\n",
    "            id_read1 = sample[\"File accession\"]\n",
    "            sample_paired = experiment.loc[experiment[\"Paired with\"] ==  id_read1].iloc[0]\n",
    "            id_read2 = sample_paired[\"File accession\"]\n",
    "                        \n",
    "            # if we haven't already processed the sample, print the results\n",
    "            if id_read1 not in samples_processed :\n",
    "                print \"paired-ended\"\n",
    "                print id_read1, sample[\"File download URL\"]\n",
    "                print id_read2, sample_paired[\"File download URL\"]\n",
    "\n",
    "            # add the paired samples to the list of samples that we processed\n",
    "            samples_processed.append(id_read1)\n",
    "            samples_processed.append(id_read2)\n",
    "        elif sample[\"Run type\"] ==  \"single-ended\" :\n",
    "            print \"single-ended\"\n",
    "            print sample[\"File accession\"], sample[\"File download URL\"]\n",
    "        \n",
    "        # increment the replicate index\n",
    "        replicate_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines of code will do the trick. Now there is the question on how to quantify the expression from single-ended RNA-seq experiments. Kallisto wants the fragment size (average and standard deviation) as input to its algorithm. However, it might be difficult to extract that information from large amounts of experiments.\n",
    "\n",
    "I read online that there is a better alternative: salmon.\n",
    "\n",
    "I ran the quantification algorithm from salmon. I want to compare the results of the two algorithms.\n",
    "\n",
    "I will switch to an R notebook to do this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
