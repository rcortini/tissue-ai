{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-10-12 FASTQ and map\n",
    "Here I want to experiment whether it is feasible to take the raw FASTQ files, map them, and use the feature counting methods available on the market to produce a standardized, uniform set of files that we can then use in successive analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "tissue_ai_rootdir = \"../\"\n",
    "datadir = \"%s/data\"%(tissue_ai_rootdir)\n",
    "md_fname = \"%s/metadata.txt\"%(datadir)\n",
    "md = pd.read_csv(md_fname, sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the files in the metadata list that correspond to raw FASTQ files. The FASTQ files correspond either to single-ended runs or paired-ended runs, and the two cases need to be treated differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselect the files that have FASTQ as type\n",
    "fastqs = md.loc[md[\"File format\"] == \"fastq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check whether the experiments have a single-ended or paired-ended flavour\n",
    "for index, sample in fastqs.iterrows() :\n",
    "    if sample[\"Run type\"] != 'paired-ended' and sample[\"Run type\"] != 'single-ended':\n",
    "        raise ValueError(\"Unrecognized run type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so all the samples are either one or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pick an example sample in the list\n",
    "i = 0\n",
    "sample = fastqs.loc[i]\n",
    "\n",
    "if sample[\"Run type\"] == 'paired-ended' :\n",
    "    sample_id = sample[\"File accession\"]\n",
    "    sample_paired = fastqs.loc[fastqs[\"Paired with\"] == sample_id]\n",
    "\n",
    "print sample[\"Experiment accession\"]\n",
    "print sample_paired[\"Experiment accession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of all the experiments\n",
    "experiments = fastqs[\"Experiment accession\"].unique()\n",
    "len(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the samples corresponding to an experiment\n",
    "experiment = experiments[34]\n",
    "samples = fastqs.loc[fastqs[\"Experiment accession\"] == experiment]\n",
    "n = 0\n",
    "for index, sample in samples.iterrows() :\n",
    "    print sample[\"File accession\"], sample[\"Paired with\"]\n",
    "    n += 1\n",
    "    if n == 1 : break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a directory in `scratch/test_map` to play around with this data. First, I download the raw FASTQ files, then I try to map them.\n",
    "\n",
    "1. BWA: 28% unmapped reads, took about 17 minutes with 16 cores and was using about 23 Gb of RAM. I read online that for RNA-seq you should use a splicing-aware aligner, such as STAR.\n",
    "\n",
    "2. STAR: basically the same results as before\n",
    "\n",
    "3. kallisto: this program is much more adequate and accurate for quantification of transcriptome in RNA-seq data. It is much faster and much lighter in terms of memory consumption. It requires only the sequences of the transcripts, which means that the quantification of expression is alignment-free"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
